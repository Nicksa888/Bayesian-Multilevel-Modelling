
# Bayesian Multilevel Models ----------------------------------------------

rm(list = ls()) 
# clear global environment to remove all loaded data sets, functions and so on.


# Libraries ---------------------------------------------------------------

library(lme4)
library(MCMCglmm)


# Load Data ---------------------------------------------------------------

prime_time <- read.csv("C:/R Portfolio/PrimeTime.csv")
glimpse(prime_time)
prime_time.nomiss <- na.omit(prime_time)
model1.1 <- MCMCglmm(geread ~ gevocab, random = ~school, 
                   data = prime_time.nomiss)

plot(model1.1)

# MCMCglmm does not accommodate the presence of missing data. Therefore, before conducting the analysis we needed to expunge all of the observations with missing data. We created a dataset with no missing observations using the command prime _time.nomiss <-na.omit(prime _ time), which created a new data frame called prime _ time.nomiss containing no missing data. The random=~ statement indicates the random effect. It is important to note that by default, MCMCglmm uses 13,000 iterations of the MCMC algorithm, with a burn-in of 3,000 and thinning of 10. As we will see below, we can easily adjust these settings to best suit our specific analysis problem.
# Prior to looking at the parameter estimates, we want to assess the autocorrelation of the estimates in the time series for each parameter. Our purpose here is to ensure that the rate of thinning (taking every tenth observation generated by the MCMC algorithm) that we used is sufficient to ensure that any autocorrelation in the estimates is eliminated. In order to obtain the autocorrelations for the random effects, we use the command autocorr(model1.1$VCV), and obtain the following results

autocorr(model1.1$VCV)


school        units
Lag 0    1.000000000 -0.055506167
Lag 10   0.041691060  0.005664999
Lag 50  -0.005121444 -0.038219136
Lag 100 -0.039402003  0.011374749
Lag 500  0.022119010 -0.016301587

, , units

school        units
Lag 0   -0.0555061673  1.000000000
Lag 10  -0.0709226015 -0.051812534
Lag 50   0.0056843812  0.049148331
Lag 100  0.0009222634 -0.002975774
Lag 500  0.0012266261 -0.003525258

# We read this table as follows: in the first section, we see results for the random effect school. This output includes correlations involving the school variance component estimates. Under the school column are the actual auto correlations for the school random effect estimate. Under the units column are the cross correlations between estimates for the school random effect and the residual random effect, at different lags. Thus, for example, the correlation between the estimates for school and the residual with no lag is –0.0549. The correlation between the school estimate 10 lags prior to the current residual estimate is −0.035. In terms of ascertaining whether our rate of thinning is sufficient, the more important numbers are in the school column, where we see the correlation between a given school effect estimate and the school effect estimate 10, 50, 100, and 500 estimates before. The autocorrelation at a lag value of 10, −0.0393, is sufficiently small for us to have confidence in our thinning the results at 10. We would reach a similar conclusion regarding the autocorrelation of the residual (units), such that 10 appears to be a reasonable thinning value for it as well. We can obtain the auto correlations of the fixed effects using the command auto corr(model1.1$Sol). Once again, it is clear that there is essentially no autocorrelation as far out as a lag of 10, indicating that the default thinning value of 10 is sufficient for both the intercept and the vocabulary test score.

# Having established that the parameter estimates have converged properly, and that our rate of thinning in the sampling of MCMCderived values is sufficient to eliminate any autocorrelation in the estimates, we are now ready to examine the specific parameter estimates for our model. The output for this analysis appears below.

summary(model1.1)

Iterations = 3001:12991
Thinning interval  = 10
Sample size  = 1000 

DIC: 105219.7 

G-structure:  ~school

post.mean l-95% CI u-95% CI eff.samp
school     39.34     25.7    54.09     1000

R-structure:  ~units

post.mean l-95% CI u-95% CI eff.samp
units       881    859.3    903.1     1108

Location effects: geread ~ gevocab 

post.mean l-95% CI u-95% CI eff.samp  pMCMC    
(Intercept)    1.8089   0.7432   2.9668     1121  0.002 ** 
  gevocab        0.7792   0.7673   0.7918     1000 <0.001 ***
  ---
  Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

# We are first given information about the number of iterations, the thinning interval, and the final number of MCMC values that were sampled (Sample size) and used to estimate the model parameters. Next, we have the model fit index, the DIC, which can be used for comparing various models and selecting the one that provides optimal fit. The DIC is interpreted in much the same fashion as the AIC and BIC, which we discussed in earlier chapters, and for which smaller values indicate better model fit. We are then provided with the posterior mean of the distribution for each of the random effects, school and residual, which MCMCglmm refers to as units. The mean variance estimate for the school random effect is 0.09962, with a 95% credibility interval of 0.06991 to 0.1419. Remember that we interpret credibility intervals in Bayesian modeling in much the same way that we interpret confidence intervals in frequentist modeling. This result indicates that reading achievement scores do differ across schools, because 0 is not in the interval. Similarly, the residual variance also differs from 0. With regard to the fixed effect of vocabulary score, which had a mean posterior value of 0.5131, we also conclude that the results are statistically significant, given that 0 is not in its 95% credibility interval. We also have a p-value for this effect, and the intercept, both of which are significant with values lower than 0.05. The positive value of the posterior mean indicates that students with higher vocabulary scores also had higher reading scores.

# In order to demonstrate how we can change the number of iterations, the burn-'in period, and the rate of thinning in R, we will reestimate Model1.1 with 100,000 iterations, a burn-in of 10,000, and a thinning rate of 50. This will yield 1,800 samples for the purposes of estimating the posterior distribution for each model parameter. The R commands for fitting this model, followed by the relevant output, appear below.

model1.1b <- MCMCglmm(geread ~ gevocab, random = ~school, 
                    data = prime_time.nomiss, 
                    nitt = 100000, 
                    thin = 50, 
                    burnin = 10000)
plot(model1.1b)
summary(model1.1b)

# 2 Level Predictors with MCMCglmm ----------------------------------------

# n addition to understanding the extent to which reading achievement is related to vocabulary test score, we may also be interested in the relationship of school (senroll), a level-2 variable, and reading achievement. Including a level-2 variable in the analysis with MCMCglmm is just as simple as doing so using lme or lme4.

model1.2 <- MCMCglmm(geread ~ gevocab + senroll, 
                     random = ~school, 
                     data = prime_time.nomiss)
plot(model1.2)

summary(model1.2)

Iterations = 3001:12991
Thinning interval  = 10
Sample size  = 1000 

DIC: 105219.8 

G-structure:  ~school

post.mean l-95% CI u-95% CI eff.samp
school     35.94    22.45    49.89     1000

R-structure:  ~units

post.mean l-95% CI u-95% CI eff.samp
units     880.8    858.7    905.9     1000

Location effects: geread ~ gevocab + senroll 

post.mean  l-95% CI  u-95% CI eff.samp  pMCMC    
(Intercept)  7.130613  3.655503 10.837877   1000.0 <0.001 ***
  gevocab      0.779819  0.767152  0.792285    753.5 <0.001 ***
  senroll     -0.010732 -0.018011 -0.004354   1000.0 <0.001 ***
  ---
  Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

# the posterior mean estimate and associated 95% credible interval for this parameter show that senroll was statistically significantly related to reading achievement; i.e. 0 is not in the interval. Taken together, we would conclude that school size does contribute significantly to the variation in reading achievement scores, and to the overall fit of the model.

# As a final separate example in this section, we will fit a random coefficients model, in which we allow the relationship of vocabulary score and reading achievement to vary across schools. The syntax for fitting this model with MCMCglmm appears below.

model1.3 <- MCMCglmm(geread ~ gevocab, 
                   random = ~school + gevocab, 
                   data = prime_time.nomiss)


summary(model1.3)

Iterations = 3001:12991
Thinning interval  = 10
Sample size  = 1000 

DIC: 105219.5 

G-structure:  ~school

post.mean l-95% CI u-95% CI eff.samp
school     38.95    25.89    54.39    899.1

~gevocab

post.mean  l-95% CI  u-95% CI eff.samp
gevocab 7.647e-07 5.806e-15 1.906e-06    56.61

R-structure:  ~units

post.mean l-95% CI u-95% CI eff.samp
units     879.9    859.1    902.5     1000

Location effects: geread ~ gevocab 

post.mean l-95% CI u-95% CI eff.samp  pMCMC    
(Intercept)    1.8036   0.7110   2.9521   1000.0  0.002 ** 
  gevocab        0.7794   0.7676   0.7922    889.6 <0.001 ***
  ---
  Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

# In the model results, we should note that the DIC for this random coefficients model is smaller than that of the random intercepts only models above. In addition, the estimate of the random coefficient for vocabulary is 7.647e-07, with a 95% credible interval of 0.7676 to 0.7922. Because this interval does not include 0, we can conclude that the random coefficient is indeed different from 0 in the population, and that the relationship between reading achievement and vocabulary test score varies from one school to another.

# MCMCglmm for a Dichotomous Dependent Variable -------------------------------------

# The MCMCglmm library can also be used to fit multilevel models in which  the outcome variable is dichotomous in nature. In most respects, the use  of the functions from this library will be very similar to what we have  seen with a continuous outcome, as described previously. Therefore, we will focus on aspects of model fitting that differ from what we have seen up to this point. Our first example involves fitting a model for a dichotomous dependent variable using Bayesian multilevel logistic regression. Specifically, the model of interest involves predicting whether or not a student receives a passing score on a state math assessment (score2) as a function of their number sense (numsense) score on a formative math assessment. Following is the R code for fitting this model, and then requesting the plots and output.

mathfinal <- read.csv("C:/R Portfolio/mathfinal.csv")

mathfinal.nomiss <- na.omit(mathfinal)
model1.4 <- MCMCglmm(score2 ~ specialed, 
                     random = ~ school, 
                     family = "ordinal", 
                     data = mathfinal.nomiss)

summary(model1.4)

Iterations = 3001:12991
Thinning interval  = 10
Sample size  = 1000 

DIC: 7528.082 

G-structure:  ~school

post.mean l-95% CI u-95% CI eff.samp
school    0.5564    0.132    1.207    2.493

R-structure:  ~units

post.mean l-95% CI u-95% CI eff.samp
units     4.461    1.197    9.386     1.75

Location effects: score2 ~ specialed 

post.mean l-95% CI u-95% CI eff.samp  pMCMC    
(Intercept)    0.5228   0.1860   0.9095   12.021 <0.001 ***
  specialed     -1.3794  -2.2058  -0.7666    4.225 <0.001 ***
  ---
  Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

# In terms of model parameter estimation results, the specialed score was found to be statistically significantly related to whether or not a student received a passing score on the state mathematics assessment. The posterior mean for the coefficient is -1.3794, indicating that the higher an individual’s specialed score, the less the likelihood that (s)he will pass the state assessment

# MCMCglmm for a Count Dependent Variable ---------------------------

# Here, we are interested in comparing the frequency of cardiac warning signs between the twwhile controlling for the sex of the patient

heartdata <- read.csv("C:/R Portfolio/rehab.csv")

str(heartdata)

model1.6 <- MCMCglmm(heart ~ trt + sex, 
                   random = ~ rehab, 
                   family = "poisson", 
                   data = heartdata)

summary(model1.6)

Iterations = 3001:12991
Thinning interval  = 10
Sample size  = 1000 

DIC: 2735.616 

G-structure:  ~rehab

post.mean l-95% CI u-95% CI eff.samp
rehab    0.5337  0.05317    0.965    316.7

R-structure:  ~units

post.mean l-95% CI u-95% CI eff.samp
units     6.114    5.116    7.146    374.5

Location effects: heart ~ trt + sex 

post.mean l-95% CI u-95% CI eff.samp  pMCMC    
(Intercept)  -0.97001 -1.23253 -0.68282    557.0 <0.001 ***
  trt          -0.22673 -0.41174 -0.01722    807.4  0.014 *  
  sex          -0.35463 -0.54938 -0.17559   1000.0 <0.001 ***
  ---
  Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

# In terms of the primary research question, the results indicate that the frequency of cardiac risk signs was lower among those in the treatment condition than those in the control, when accounting for the participants’ sex. In addition, there was a statistically significant difference in the rate of risk symptoms between males and females. With respect to the random effects, the variance in the outcome variable due to rehabilitation facility, as well as the residual, were both significantly different from 0. The posterior mean effect of the rehab facility was 0.5414, with a 95% credibility interval of 0.5337 to 0.05317. This result indicates that symptom frequency does differ among the facilities.

# We may also be interested in examining a somewhat more complex explanation of the impact of treatment on the rate of cardiac symptoms. For instance, we may suspect taht the number of hours the facilities are open may impact the frequency of cardiac symptoms, by providing more, or less, opportunity for patients to make use of their services. In turn, if more participation in rehabilitation activities is associated with the frequency of cardiac risk symptoms, we might expect the hours of operation to impact them. In addition, it is believed that the impact of the treatment on the outcome might vary among rehabilitation centers, leading to a random coefficients model. The R commands to fit the random coefficients (for treatment) model, with a level-2 covariate (hours of operation) appear below, followed by the resulting output. Note that, as we have seen in previous examples in this chapter, in order to specify a random coefficients model, we include the variables of interest (rehab and hours) in the random statement

model1.7 <- MCMCglmm(heart ~ trt + sex + hours, 
                     random = ~rehab + trt, 
                     family = "poisson", 
                     data = heartdata)

summary(model1.7)

Iterations = 3001:12991
Thinning interval  = 10
Sample size  = 1000 

DIC: 2726.689 

G-structure:  ~rehab

post.mean l-95% CI u-95% CI eff.samp
rehab    0.5724  0.01013    1.003    106.8

~trt

post.mean l-95% CI u-95% CI eff.samp
trt     2.942  0.05754    6.402    3.284

R-structure:  ~units

post.mean l-95% CI u-95% CI eff.samp
units     3.243   0.0306     6.26    3.902

Location effects: heart ~ trt + sex + hours 

post.mean l-95% CI u-95% CI eff.samp  pMCMC    
(Intercept)  -0.99737 -1.27055 -0.74016    323.8 <0.001 ***
  trt          -0.22049 -0.42937 -0.02313    388.7  0.042 *  
  sex          -0.35544 -0.52767 -0.15774    534.9 <0.001 ***
  hours         0.01312 -0.23315  0.27259    826.5  0.952    
---
  Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

# The results of the model fitting revealed several interesting patterns. First, the random coefficient term for treatment was statistically significant. Thus, we can conclude that the impact of treatment on the number of cardiac symptoms differs from one rehabilitation center to the next. In addition, the variance in the outcome due to rehabilitation center was also different from 0. Finally, treatment and sex were negatively statistically significantly related to the number of cardiac symptoms, as they were for  and the centers’ hours of operation were not related to the number of cardiac symptoms.
